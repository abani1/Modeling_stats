
\section{Models and assumptions}
We present in this paper a simple data driven approach to discriminate among models and the modeling assumptions implicit in each model, given a range of phenomena to be studied. We illustrate the approach by work on geophysical mass flows.
This is especially relevant when the observations/measurements are not adequate to characterize the behavior of the system which is modeled. Observational {\it data inadequacy} is rarely characterized even for verified and validated models. 

Since models actualize a hypothesis, it follows  that a model is a formulation of a belief about the data. The immediate consequence of this is that the model may not be reliable about such prediction, since the {\it subjectivity of the belief} can never be completely eliminated \citep{Kennedy2001, Higdon2004}, nor is  the data at hand  enough to characterize its behavior at the desired prediction. Principles like ``Occam's razor" and Bayesian statistics \citep{Farrell2015} provide some guidance, but simple robust approaches that allow the testing of models for fitness need to be developed. In related work we have shown that, the itemized application of the empirical falsification principle of  Popper \citep{Popper1959} over an arbitrarily wide envelope of possible input conditions was shown to reduce the subjectivity of the belief in a case study where the available data was not adequate \citep{Bevilacqua2019}.%
%{\bf NEED to MOTIVATE WITH SYSTEM COMPLEXITY and MANY MODELS?}

For complex systems with sparse observations, like large scale geophysical mass flows, there  are usually numerous models, e.g., \cite{Kelfoun2011}. It is often difficult to decide which of these models are appropriate for a particular analysis. Nevertheless, ready availability of many models as reusable software tools makes it the user's burden to select one appropriate for their purpose.
For example, the $\mathrm{4^{\mathrm{th}}}$ release of TITAN2D\footnote{available from vhub.org} offers multiple rheology options in the same code base. Remarkably, the availability of several distinct models for similar phenomena in the same tool provides us the ability to directly compare outputs and internal variables in all the models and control for usually difficult to quantify effects like numerical solution procedures, input ranges and computer hardware. This can improve the process for integrating information from multiple models \citep{Bongard2007}. Given a particular problem for which predictive analysis is planned, the information generated and its comparison to available observational data can be used to guide model choice and input space refinement \citep{Bevilacqua2019}.
However, as we have discovered such comparison requires a more careful understanding of each model and its constituents and a well organized process for such comparison. %We begin with precise, albeit limited definitions of models and their constituents.

%This paper presents a systematic approach to the study of such models of complex systems, motivated by and applied to the case of geophysical mass flow models.
In this study we describe a methodology for characterizing geophysical flow models and the modeling assumptions they represent. A modeling assumption is a simple concept -- any atomic postulate about relationships among quantities under study. Models are compositions of many such assumptions. The study of models is, thus, implicitly a study of these assumptions and their composability and applicability in a particular context. Sometimes a good model contains a useless assumption that may be removed, sometimes a good assumption could be added to a different model - these are usually subjective choices, not data driven. Moreover, the correct assumptions may change as the system evolves, making {\em model choice} more difficult.


In this study, we initially provide a traditional type of analysis, summarizing the general features that differ among the model outputs. However, this is performed in a probabilistic framework, oriented to extrapolation and forecast. After that, and more significantly, we describe and compare the general features of the newly introduced \emph{contributing variables} in the models, through the new concepts of dominance factors and expected contributions. This is a type of analysis enabled by our approach, that allows us to evaluate modeling assumptions and their relative importance. 

